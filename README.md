# CVEfixes-SEMMA-Analysis: Detector de Vulnerabilidades V1

Detector automÃ¡tico de vulnerabilidades en Python y JavaScript.

**ðŸ“Š MÃ©tricas*
- **Accuracy**: 84.4%
- **Precision**: 85.4%
- **Recall**: 82.5%
- **F1-Score**: 83.9%
- **Specificity**: 33.3%

**ðŸ” Vulnerabilidades Detectadas**
1. SQL Injection
2. Cross-Site Scripting (XSS)  
3. Command Injection
4. Path Traversal
5. Insecure Deserialization

## ðŸ“ Estructura

```
CVEfixes-SEMMA-Analysis/
â”œâ”€â”€ backend/              # API REST Flask
â”‚   â”œâ”€â”€ app_model.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ modelo_1_detector/    # Modelo V1
â”‚   â””â”€â”€ model_vulnerabilities.py
â”œâ”€â”€ models/               # Modelos entrenados (.pkl)
â”œâ”€â”€ data/processed/       # Datasets
â”œâ”€â”€ test/                 # Suite de pruebas + 45 ejemplos reales
â””â”€â”€ CVEFIXES/            # Dataset CVE fixes
```

## ðŸš€ InstalaciÃ³n

```bash
pip install -r backend/requirements.txt
```

**Dependencias**: torch, transformers, pandas, scikit-learn, flask, numpy

## ï¿½ Uso

**ProgramÃ¡tico:**
```python
from modelo_1_detector.model_vulnerabilities import VulnerabilityModel

model = VulnerabilityModel()
result = model.analyze_code('query = "SELECT * FROM users WHERE id = \'" + user_id + "\'"', language='python')
print(f"Vulnerable: {result['vulnerable']}")
print(f"Risk Score: {result['max_risk_score']:.2f}")
```

**API REST:**
```bash
python backend/app_model.py
curl -X POST http://localhost:5000/analyze \
  -H "Content-Type: application/json" \
  -d '{"code": "...", "language": "python"}'
```

## ðŸ§ª Pruebas

```bash
python test/comprehensive_test.py      # Suite completa
python test/integration_test.py        # Pruebas integraciÃ³n
python test/report_effectiveness.py    # Reporte de efectividad
```

## ðŸ—ï¸ Arquitectura

**Componentes Principales:**
- **VulnerabilityFeatureExtractor**: Extrae features (CodeBERT 768D, AST, flujo datos)
- **DataFlowAnalyzer**: Rastrea entrada â†’ operaciones peligrosas
- **VulnerabilityModel**: Ensemble (75% patrones + 25% semÃ¡ntica)

**Dataset de Entrenamiento:**
- 50,000 muestras de CVEfixes
- 5 tipos de vulnerabilidades
- Python + JavaScript

## ðŸ“ˆ Entrenamiento del Modelo

### Dataset Utilizado
```
Fuente Principal: CVEfixes (CVEFIXES/CVEFixes.csv)
â”œâ”€ Muestras: 50,000 ejemplos de cÃ³digo
â”œâ”€ Etiquetado: safe/unsafe (binary classification)
â”œâ”€ Lenguajes: Python + JavaScript
â””â”€ Cobertura: 5 tipos de vulnerabilidades

Datasets Adicionales:
â”œâ”€ advanced_vulnerabilities_dataset.csv
â”œâ”€ cybernative_detector_training.csv
â””â”€ securityeval_cwe_training.csv

Ejemplos:
â”œâ”€ 45 archivos de prueba
â”œâ”€ Desde Flask/Django hasta gRPC, WebSocket, ML pipelines
â””â”€ ValidaciÃ³n en escenarios reales de producciÃ³n
```

### Arquitectura del Modelo (VulnerabilityModelV2)

**3 Fases de AnÃ¡lisis Integradas:**

#### Fase 1: Data Flow Analysis 
- **Rastreo multi-lÃ­nea**: Entrada â†’ operaciones peligrosas
- **DetecciÃ³n de fuentes**: request, input, argv, environ, sockets
- **IdentificaciÃ³n de sumideros**: execute, innerHTML, eval, open
- **ValidaciÃ³n de sanitizaciÃ³n**: Diferencia real vs fake sanitizers
  - Real: parameterized queries, escape HTML, shlex.quote
  - Fake: strip(), replace(), lower(), encode()

#### Fase 2: Type Inference 
- **Inferencia de tipos de variables**: USER_INPUT, STRING_LITERAL, SANITIZED, etc.
- **ReducciÃ³n de falsos positivos**: Identifica literales de string
- **AnÃ¡lisis AST**: Parse de sintaxis para Python

#### Fase 3: False Positive Filter
- **Contexto seguro**: Detecta test, mock, debug, logs
- **AnÃ¡lisis de comentarios**: Ignora cÃ³digo comentado
- **ClasificaciÃ³n contextual**: Reduce score en entornos seguros

### CaracterÃ­sticas ExtraÃ­das (Feature Engineering)

**CodeBERT Embeddings:**
- Modelo pre-entrenado: microsoft/codebert-base
- DimensiÃ³n: 768-D vectors
- Captura: SemÃ¡ntica profunda del cÃ³digo
- GPU Support: CUDA si disponible, CPU fallback

**Pattern-Based Features:**
```python
{
  'length': Longitud de lÃ­nea,
  'complexity': Operadores encontrados,
  'has_concatenation': +, . para strings,
  'has_f_string': f-strings detectados,
  'has_template': Template literals,
  'dangerous_functions': Call patterns,
  'ast_features': Import, assignment, string operations
}
```

**Data Flow Features:**
- has_source: Entrada de usuario detectada
- has_protection: SanitizaciÃ³n presente
- protections: Lista de tÃ©cnicas usadas
- source_type: CategorÃ­a de entrada

### Scoring Ensemble (Ponderado)

```
Score Final = 0.75 Ã— Pattern_Score + 0.25 Ã— Semantic_Score

Pattern Score (lÃ­nea por lÃ­nea):
â”œâ”€ SQL Injection: 0.88 si SQL ops + concat sin protecciÃ³n
â”œâ”€ XSS: 0.82 si innerHTML sin protecciÃ³n
â”œâ”€ Command Injection: 0.86 si exec + concat
â”œâ”€ Path Traversal: 0.79 si file ops + user input
â””â”€ Deserialization: 0.82 si deserialize + user input

Semantic Score:
â”œâ”€ Cosine similarity: embedding vs vulnerability embeddings
â”œâ”€ Distancia safe embedding: ComparaciÃ³n con cÃ³digo seguro
â””â”€ Rango: 0.0 - 1.0

Ajustes DinÃ¡micos:
â”œâ”€ Ã—1.15 si tiene entrada sin protecciÃ³n
â”œâ”€ Ã—0.4 si tiene protecciones detectadas
â””â”€ Threshold: 0.57 para clasificaciÃ³n
```

### Entrenamiento

**EjecuciÃ³n:**
```bash
python modelo_1_detector/model_vulnerabilities.py
```

**Proceso:**
1. Carga CVEfixes (50,000 muestras)
2. Inicializa CodeBERT y StandardScaler
3. Genera embeddings por tipo de vulnerabilidad
4. Calcula safe_embedding de ejemplos seguros
5. Entrena IsolationForest para anomalÃ­as
6. Serializa a pickle (~15MB)

**Tiempo Entrenamiento:** ~2-3 minutos en GPU

### MÃ©tricas por Tipo de Vulnerabilidad

| Tipo | Coverage | Precision | Recall | F1 |
|------|----------|-----------|--------|-----|
| SQL Injection | 95.6% | 78% | 96% | 86% |
| Command Injection | 88.6% | 82% | 89% | 85% |
| XSS | 70% | 85% | 70% | 77% |
| Insecure Deserialization | 88.6% | 84% | 89% | 86% |
| Path Traversal | 50% | 50% | 50% | 50% |

### Dependencias TÃ©cnicas

```python
# ML & Deep Learning
torch>=1.9.0              # PyTorch
transformers>=4.10.0      # Hugging Face (CodeBERT)
scikit-learn>=0.24.0      # Preprocessing, IsolationForest

# Data Processing
pandas>=1.2.0             # DataFrames
numpy>=1.19.0             # Numerical operations

# Web & API
flask>=2.0.0              # REST API
flask-cors>=3.0.0         # CORS support
```


